{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [],
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1\"><a href=\"#VARIABLE-DESCRIPTIONS:\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>VARIABLE DESCRIPTIONS:</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q numpy scikit-learn ipython matplotlib pandas sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bf6d6733-3a02-4507-b9d1-f1308c35fa58"
   },
   "source": [
    "# VARIABLE DESCRIPTIONS:\n",
    "\n",
    "* survival        Survival            (0 = No; 1 = Yes)\n",
    "* pclass          Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "* name            Name\n",
    "* sex             Sex\n",
    "* age             Age\n",
    "* sibsp           Number of Siblings/Spouses Aboard\n",
    "* parch           Number of Parents/Children Aboard\n",
    "* ticket          Ticket Number\n",
    "* fare            Passenger Fare\n",
    "* cabin           Cabin\n",
    "* embarked        Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "adb23194-250e-44d9-8dad-524de9c54bbf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genderclassmodel.csv  gendermodel.csv  test.csv  train.csv  train.csv.ori\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries \n",
    "# installed\n",
    "# It is defined by the kaggle/python docker image: \n",
    "# https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    FunctionTransformer, OneHotEncoder, StandardScaler,\n",
    "    MinMaxScaler, MaxAbsScaler\n",
    ")\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import sklearn\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) \n",
    "# will list the files in the input directory\n",
    "\n",
    "import sh\n",
    "print(sh.ls('./input'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "e703e996-ca79-4c6a-ace1-bed7e5010918",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set has 418 rows and 11 columns.\n",
      "test set has 418 rows and 2 columns.\n",
      "train set has 891 rows and 12 columns.\n"
     ]
    }
   ],
   "source": [
    "Y_test =  pd.read_csv('./input/genderclassmodel.csv')\n",
    "test =  pd.read_csv('./input/test.csv')\n",
    "train =  pd.read_csv('./input/train.csv')\n",
    "\n",
    "print('test set has %s rows and %s columns.' % test.shape)\n",
    "print('test set has %s rows and %s columns.' % Y_test.shape)\n",
    "print('train set has %s rows and %s columns.' % train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, p_unique=0.2):\n",
    "    df = df.copy()\n",
    "    \n",
    "    size = len(df)\n",
    "    \n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    for c in cols:\n",
    "        if df[c].dtype == object:\n",
    "            if df[c].nunique()/size > p_unique:\n",
    "                df.drop(c, axis=1, inplace=True)\n",
    "                continue\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = make_pipeline(\n",
    "    SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    StandardScaler(),\n",
    "    PCA(random_state=42)\n",
    ")\n",
    "\n",
    "pca.fit_transform(prepare_df(train.drop('Survived', axis=1)), train.Survived);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('simpleimputer', SimpleImputer()),\n",
       "  ('standardscaler', StandardScaler()),\n",
       "  ('pca', PCA(random_state=42))],\n",
       " 'verbose': False,\n",
       " 'simpleimputer': SimpleImputer(),\n",
       " 'standardscaler': StandardScaler(),\n",
       " 'pca': PCA(random_state=42),\n",
       " 'simpleimputer__add_indicator': False,\n",
       " 'simpleimputer__copy': True,\n",
       " 'simpleimputer__fill_value': None,\n",
       " 'simpleimputer__keep_empty_features': False,\n",
       " 'simpleimputer__missing_values': nan,\n",
       " 'simpleimputer__strategy': 'mean',\n",
       " 'standardscaler__copy': True,\n",
       " 'standardscaler__with_mean': True,\n",
       " 'standardscaler__with_std': True,\n",
       " 'pca__copy': True,\n",
       " 'pca__iterated_power': 'auto',\n",
       " 'pca__n_components': None,\n",
       " 'pca__n_oversamples': 10,\n",
       " 'pca__power_iteration_normalizer': 'auto',\n",
       " 'pca__random_state': 42,\n",
       " 'pca__svd_solver': 'auto',\n",
       " 'pca__tol': 0.0,\n",
       " 'pca__whiten': False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = train.copy()\n",
    "\n",
    "train_.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "# train_.dropna(inplace=True)\n",
    "\n",
    "X_train = prepare_df(train_.drop('Survived', axis=1))\n",
    "y_train = train_[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ = pd.concat([Y_test, test.iloc[:, 1:]], axis=1)\n",
    "\n",
    "test_.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "# test_.dropna(inplace=True)\n",
    "\n",
    "X_test = prepare_df(test_.drop('Survived', axis=1))\n",
    "y_test = test_[['Survived']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test set has 418 rows and 8 columns.\n",
      "y_test set has 418 rows and 1 columns.\n",
      "X_train set has 891 rows and 8 columns.\n",
      "Y_train set has 891 rows and 1 columns.\n"
     ]
    }
   ],
   "source": [
    "print('X_test set has %s rows and %s columns.' % X_test.shape)\n",
    "print('y_test set has %s rows and %s columns.' % y_test.shape)\n",
    "print('X_train set has %s rows and %s columns.' % X_train.shape)\n",
    "print('Y_train set has %s rows and %s columns.' % y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# , MaxAbsScaler\n",
    "pipeline_rfc = make_pipeline(\n",
    "    SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    MaxAbsScaler(),\n",
    "    RandomForestClassifier(random_state=42)\n",
    ")\n",
    "\n",
    "pipeline_svc = make_pipeline(\n",
    "    SimpleImputer(missing_values=np.nan, strategy='mean'),\n",
    "    MaxAbsScaler(),\n",
    "    SVC()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
      "                ('maxabsscaler', MaxAbsScaler()),\n",
      "                ('randomforestclassifier',\n",
      "                 RandomForestClassifier(random_state=42))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmn/miniforge3/envs/datateller-web/lib/python3.11/site-packages/sklearn/base.py:1474: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score\n",
      "0.75\n",
      "precision score\n",
      "0.7161290322580646\n",
      "accuracy score\n",
      "0.8229665071770335\n",
      "\n",
      "Pipeline(steps=[('simpleimputer', SimpleImputer()),\n",
      "                ('maxabsscaler', MaxAbsScaler()), ('svc', SVC())])\n",
      "f1 score\n",
      "0.873015873015873\n",
      "precision score\n",
      "0.990990990990991\n",
      "accuracy score\n",
      "0.9234449760765551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xmn/miniforge3/envs/datateller-web/lib/python3.11/site-packages/sklearn/utils/validation.py:1300: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "for title, model in {\n",
    "    'RandomForestClassifier': pipeline_rfc, \n",
    "    'SVC': pipeline_svc\n",
    "}.items():\n",
    "    print('\\n%s' % model)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    predicted = model.predict(X_test)\n",
    "    print('f1 score')\n",
    "    print(f1_score(y_test, predicted))\n",
    "    print('precision score')\n",
    "    print(precision_score(y_test, predicted))\n",
    "    print('accuracy score')\n",
    "    print(accuracy_score(y_test, predicted))\n",
    "    f_name = 'output/%s.csv' % title\n",
    "    \n",
    "    # np.savetxt(f_name, predicted)\n",
    "    # print('%s saved!' % f_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
